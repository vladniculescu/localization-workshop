{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d1f4e1-8491-4c53-bb95-27df36d1155e",
   "metadata": {},
   "source": [
    "# Part 1: Trilateration - Difference of Squares Algorithm\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./circles.png\" alt=\"Trilateration Illustration\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "### Problem Description:\n",
    "The **goal** is to determine the coordinates of an unknown point $P(x, y)$ given the coordinates of **N** known points $P_1(x_{0}, y_{0}), P_1(x_{1}, y_{1}), \\dots, P_{N-1}(x_{N-1}, y_{N-1})$ and their respective distances to the unknown point: $d_0, d_1, \\dots, d_{N-1}$.\n",
    "\n",
    "By elementary geometry, the following equations hold:\n",
    "\n",
    "$$\n",
    "d_i^2 = (x - x_i)^2 + (y - y_i)^2 \\quad \\text{for} \\, i = 0, 1, \\dots, N-1\n",
    "$$\n",
    "\n",
    "### Solving the Problem\n",
    "\n",
    "We can choose one of the equations (e.g., the equation for $d_0$) as a reference equation, and subtract it from all other equations.\n",
    "\n",
    "#### 1. Subtract Equation \\( i \\) from Equation 1:\n",
    "\n",
    "We subtract the distance equation for point $ P_i(x_i, y_i)$ from the distance equation for $P_0(x_0, y_0)$:\n",
    "\n",
    "$$\n",
    "d_0^2 - d_i^2 = \\left[ (x - x_0)^2 + (y - y_0)^2 \\right] - \\left[ (x - x_i)^2 + (y - y_i)^2 \\right]\n",
    "$$\n",
    "\n",
    "Expanding both sides and canceling the common terms, we get:\n",
    "\n",
    "$$\n",
    "d_0^2 - d_i^2 = -2x(x_0 - x_i) - 2y(y_0 - y_i) + (x_0^2 - x_i^2) + (y_0^2 - y_i^2)\n",
    "$$\n",
    "\n",
    "Rearranging this, we obtain the linear equation in $x$ and $y$:\n",
    "\n",
    "$$\n",
    "2x(x_i - x_0) + 2y(y_i - y_0) = d_0^2 - d_i^2 + (x_i^2 - x_0^2) + (y_i^2 - y_0^2), \\quad \\text{for} \\, i = 1, \\dots, N-1\n",
    "$$\n",
    "\n",
    "This results in \\( N-1 \\) linear equations (since we subtract one equation from the rest).\n",
    "\n",
    "\n",
    "#### 2. Put the Equation System in a Matrix Form:\n",
    "\n",
    "Once we have the system of linear equations, we can express it in matrix form as:\n",
    "\n",
    "$$\n",
    "A \\cdot [x, y]^T = b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "2(x_1 - x_0) & 2(y_1 - y_0) \\\\\n",
    "2(x_2 - x_0) & 2(y_2 - y_0) \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "2(x_{N-1} - x_0) & 2(y_{N-1} - y_0)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = \\begin{bmatrix}\n",
    "d_0^2 - d_1^2 + (x_1^2 - x_0^2) + (y_1^2 - y_0^2) \\\\\n",
    "d_0^2 - d_2^2 + (x_2^2 - x_0^2) + (y_2^2 - y_0^2) \\\\\n",
    "\\vdots \\\\\n",
    "d_0^2 - d_{N-1}^2 + (x_{N-1}^2 - x_0^2) + (y_{N-1}^2 - y_0^2)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "### Observation\n",
    "\n",
    "- At least **two** of the known points must not be collinear (i.e., they must form a triangle).\n",
    "- At least three points are necessary for the 2D case, and four points for the 3D case.\n",
    "- If more than three anchors are used in 2D, there is no exact soluton and the system should be solved as a linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a963704-6551-4d29-9f7f-0785d3496d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from trilateration_opt import trilateration_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702344de-de33-411c-9805-1b6a61a46c6e",
   "metadata": {},
   "source": [
    "## Exercise: Implement the Difference of Squares Trilateration Algorithm in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53a847-e1af-4bad-bd70-1199bac3817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def trilateration_dos(X, d):\n",
    "    \"\"\"\n",
    "    Function to compute the unknown point P in dim-dimensional Euclidean space.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): A matrix of shape (n, dim) representing the coordinates \n",
    "                       of n known points in dim-dimensional space.\n",
    "    d (numpy.ndarray): A 1D array of shape (n,) representing the distances \n",
    "                       from the unknown point to each of the known points.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: A 1D array representing the coordinates of the unknown point in dim-dimensional space.\n",
    "\n",
    "    Note: dim=2 for this exercise\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ### TODO 1 ###\n",
    "    # Complete the implementation of the trilateration function\n",
    "\n",
    "    dim = X.shape[1]\n",
    "    solution = np.zeros(dim)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cae13e-e826-49db-bed8-a00cab0443c4",
   "metadata": {},
   "source": [
    "### Scenario 1 - Robot surrounded by anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1fd226-a56e-4b22-ab41-a5f6210747d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.load('data_close.npz')\n",
    "plot_points_2d(data)\n",
    "\n",
    "# Extract input variables\n",
    "X = data['X']\n",
    "uwb_distances = data['distances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63065a-3c8f-45bc-b72b-53dd2c70e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i in range(500):\n",
    "    P_est = trilateration_dos(X, uwb_distances[i])\n",
    "    error = np.linalg.norm(P_est - data['node_pos'])\n",
    "    errors.append(error)\n",
    "    \n",
    "mean_error = np.mean(errors)\n",
    "print(\"DoS Error: \", np.round(mean_error, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9b5c8-505d-4bfa-b3fb-87abecabbd22",
   "metadata": {},
   "source": [
    "### Scenario 2 - Robot far from the anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d97950-5776-4e13-b089-e3d61679e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.load('data_far.npz')\n",
    "plot_points_2d(data)\n",
    "\n",
    "# Extract input variables\n",
    "X = data['X']\n",
    "uwb_distances = data['distances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04a22c-4195-4559-a18f-8eb4dd322daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i in range(500):\n",
    "    P_est = trilateration_dos(X, uwb_distances[i])\n",
    "    error = np.linalg.norm(P_est - data['node_pos'])\n",
    "    errors.append(error)\n",
    "    \n",
    "mean_error = np.mean(errors)\n",
    "print(\"DoS Error: \", np.round(mean_error, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2071c7-ef50-484f-8c06-e4ac00044192",
   "metadata": {},
   "source": [
    "### Additional study\n",
    "The *Difference of Squares Algorithm* does not attempt to minimize any cost function, and therefore it exhibits less robustness compared to the optimal trilateration introduced in the theoretical part of the workshop. The following cell performs the localization of **Scenario 2** using the optimal trilateration instead of the Difference of Squares Algorithm. Observe the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726326e2-9dfb-4f3e-9504-de344fcb244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i in range(500):\n",
    "    P_est = trilateration_opt(X, uwb_distances[i])\n",
    "    error = np.linalg.norm(P_est - data['node_pos'])\n",
    "    errors.append(error)\n",
    "    \n",
    "mean_error = np.mean(errors)\n",
    "print(\"Optimal Trilateration Error: \", np.round(mean_error, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932c42a-3b47-446d-9521-5b6993bd7f8a",
   "metadata": {},
   "source": [
    "# Part 2: 2D Robot Localization using an Extended Kalman Filter (EKF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15858ccf-165f-418f-b152-42d7e77e772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('ekf.npz')\n",
    "plot_robot_setup(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a927bff-006e-4004-8c98-71029b09b455",
   "metadata": {},
   "source": [
    "In this exercise, you will complete the implementation of an Extended Kalman Filter (EKF) to localize a mobile robot. The robot is equipped with a system of four fixed anchors that provide continuous distance measurements. The robot's goal is to estimate its position $(x, y)$ in 2D space using these distance measurements.\n",
    "\n",
    "The robot receives measurements of its distances to the four anchors, whose positions are known. The EKF assumes that the state is normally distributed and estimates its probability distribution: the mean $\\mathbf{x}$ and the covariance matrix $P$.\n",
    "\n",
    "### Robot State\n",
    "The robot's state is represented by the 2D position:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} = \\begin{pmatrix} x \\\\ y \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "- x is the robot's position along the x-axis,\n",
    "- y is the robot's position along the y-axis.\n",
    "\n",
    "### Distance Measurements\n",
    "The robot receives distance measurements $z_i$ from each anchor, where $i = 0, 1, 2, 3$ corresponds to the four anchors. The relation between the distance measurement and the state is given by the measurement model $h_i(\\mathbf{x}, \\eta)$:\n",
    "\n",
    "\\begin{equation}\n",
    "h_i(\\mathbf{x}, \\eta) = z_i = \\sqrt{(x - a_i)^2 + (y - b_i)^2} + \\eta, \\quad \\eta \\sim \\mathcal{N}(0, R)\n",
    "\\end{equation}\n",
    "\n",
    "where $(a_i, b_i)$ represent the coordinates of anchor $i$.  Moreover, $\\eta$ represents the normally distributed sensor noise, with zero mean and $Var(\\eta)=R$.\n",
    "\n",
    "### Extended Kalman Filter Equations\n",
    "\n",
    "The EKF is a recursive algorithm that iterates between two main steps: **Prediction** and **Update**. The goal is to keep track of $\\mathbf{x}$ and the covariance matrix $P$.\n",
    "\n",
    "#### 1. Prediction Step\n",
    "The general structure of the system dynamics is the following.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}(k+1) = A \\mathbf{x}(k) + \\mathbf{u} + \\rho, \\quad \\rho \\sim \\mathcal{N}(0, Q)\n",
    "\\end{equation}\n",
    "\n",
    "$\\mathbf{u}$ is the control input, and $\\rho$ the process noise.\n",
    "\n",
    "In the prediction step, the filter uses the robot's motion model (which could be a linear or non-linear function) to predict the new state $\\mathbf{x}$ and its covariance $P$.\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{x} &\\leftarrow A \\mathbf{x} + \\mathbf{u}\\\\\n",
    "P &\\leftarrow A P A^T + Q, \\quad Q=Var(\\rho)\n",
    "\\end{align}\n",
    "\n",
    "Where $\\mathbf{u}$ represents the control input (e.g., provided by accelerometer), and $A$ is identified fro the laws of motion.\n",
    "\n",
    "##### Particular for this exercise:\n",
    "Since this problem gives no information about the robot's motion model, we will model the dynamics with a random walk:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}(k+1) = \\mathbf{x}(k) + \\rho\n",
    "\\end{equation}\n",
    "\n",
    "Therefore, the prediction becomes:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{x} &\\leftarrow \\mathbf{x} \\\\\n",
    "P &\\leftarrow P + Q\n",
    "\\end{align}\n",
    "\n",
    "This means that since we have no information on the dynamics, the **Prediction** step does not change the state estimate $\\mathbf{x}$. However, a $Q$ matrix of $Q = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$ signifies that the uncertainty in the robot's movement from one timestamp to the next follows a normal distribution with a variance of 1 m (and zero mean).\n",
    "\n",
    "#### 2. Update Step\n",
    "\n",
    "The update step corrects the predicted state and covariance using the distance measurements from the anchors. For this purpose, it first computes the Kalman gain $K$, which determines how much weight should be given to the predicted state versus the new measurement during the state update.\n",
    "\n",
    "\\begin{equation}\n",
    "K \\leftarrow P H^T (H P H^T + R)^{-1}\n",
    "\\end{equation}\n",
    "\n",
    "- $H = \\frac{\\partial h(\\mathbf{x})}{\\partial \\mathbf{x}}$ is the Jacobian matrix of the measurement model with respect to the state $\\mathbf{x}$,\n",
    "- $R$ is the measurement noise covariance matrix. In our case a scalar.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} \\leftarrow  \\mathbf{x} + K(z - h_i(\\mathbf{x}, 0))\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P \\leftarrow (I - K H) P (I - K H)^T + K R K^T\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "<!-- The Jacobian for this measurement model with respect to the state $\\mathbf{x} = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$ is: -->\n",
    "\n",
    "<!-- \\begin{equation}\n",
    "H_i = \\begin{pmatrix} \\frac{x - a_i}{\\sqrt{(x - a_i)^2 + (y - b_i)^2}} & \\frac{y - b_i}{\\sqrt{(x - a_i)^2 + (y - b_i)^2}} \\end{pmatrix}\n",
    "\\end{equation} -->\n",
    "\n",
    "\n",
    "### Summary: Steps of the EKF Implementation\n",
    "\n",
    "1. **Initialization**:\n",
    "   - The initial values of the $\\mathbf{x}$ and $P$ are necessary. In this exercise, they are provided.\n",
    "\n",
    "2. **Prediction step**:\n",
    "   - Essentially, this step only adds variance. If the prediction step is completely skipped, the covariance will go towards zero and the filter will stop learning.\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{x} &\\leftarrow \\mathbf{x} \\\\\n",
    "P &\\leftarrow P + Q\n",
    "\\end{align}\n",
    "\n",
    "3. **Update step**:\n",
    "\\begin{align*}\n",
    "K &\\leftarrow P H^T (H P H^T + R)^{-1} \\\\\n",
    "\\mathbf{x} &\\leftarrow \\mathbf{x} + K(z - h_i(\\mathbf{x}, 0)) \\\\\n",
    "P &\\leftarrow (I - K H) P (I - K H)^T + K R K^T\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "#### Solve the exercise by complete the fields marked with \"TODO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ec0d0-30ba-4a67-8171-4f626cd9c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc727e1-db9f-4827-bfb7-f576632712d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes h_i(x, 0)\n",
    "def compute_measurement(x, anchor_xy):\n",
    "    z_comp = np.sqrt((x[0] - anchor_xy[0]) ** 2 + (x[1] - anchor_xy[1]) ** 2)\n",
    "    return z_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866222a-8b2d-45b5-abd1-663d3746d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_H(anchor, x):\n",
    "    H = np.zeros(2)\n",
    "    #####  TODO 1: Compute the jacobian H  ##### \n",
    "    H[0] = \n",
    "    H[1] = \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819abd4-f63a-435a-88d5-339fa2fbe107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(x, P, R, anchor, z):\n",
    "    xp = x.reshape(2,1)\n",
    "    H = comp_H(anchor, x).reshape(1, 2)\n",
    "    inv = 1/(dot(H, P).dot(H.T) + R)\n",
    "    K = dot(P, H.T) * inv\n",
    "    #####  TODO 2: Having the Kalman gain K, complete the update equations  ##### \n",
    "    x_upd = \n",
    "    P_upd =\n",
    "\n",
    "    return x_upd, P_upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b94c14-1cdb-4501-ae3f-e57631908e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = data['measurements']\n",
    "x0 = data['x0']\n",
    "N = len(measurements)\n",
    "\n",
    "# Filter initialization\n",
    "P = 0.01 * np.identity(2) # Note that the initial variance is small, so the filter is sure about the initial state value\n",
    "\n",
    "# Sensor noise covariance matrix\n",
    "Q = 0.1 * np.identity(2)\n",
    "\n",
    "# Sensor noise variance\n",
    "R = 0.2**2\n",
    "\n",
    "x = x0\n",
    "x_log = np.zeros((N, 2))\n",
    "for i in range(N):\n",
    "    # Prediction step\n",
    "    x = x + 0\n",
    "    P = P + Q\n",
    "    \n",
    "    # Update step\n",
    "    anchor = measurements[i, :2]\n",
    "    distance = measurements[i, 2]\n",
    "    [x, P] = update(x, P, R, anchor, distance)\n",
    "\n",
    "    # Log current state\n",
    "    x_log[i, :] = x.reshape(2)\n",
    "\n",
    "# Plot trajectory\n",
    "plot_estimated_trajectory(data, x_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7e170e-460e-442e-ac0f-3d30d1380c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1560c563-7624-4756-ad83-ca67011224a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
